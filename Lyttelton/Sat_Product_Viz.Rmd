---
title: "Sat_Product_Viz"
author: "Francois Thoral"
date: "27 April 2020"
output: html_document
runtime: shiny
---

```{r setup, include=FALSE}
library(knitr)
library(readxl)
library(raster)
library(ncdf4)
library(ggplot2)
library(maps)
library(maptools)
library(RColorBrewer)
library(sp) 
library(rgdal)
library(leaflet)
library(measurements)
library(tibbletime)
library(tibble)
library(lubridate)
library(tidyverse)
library(reshape2)
library(plotly)
library(leafem)
library(dplyr)
library(velox)
library(stringr)
```


__AIM__ : To Visualize the satellite products (SST, KPAR) as well as the in situ sites in Lyttelton harbour.

1. KPAR is estimated using satellite measurements (MODIS AQUA) of absorption and backscattering coefficients. Their spatial resolution is 500m-pixel wide.
2. SST data come from MODIS AQUA with a nominal resolution of 1km but has been downscalled to 500m-pixel wide.
3. The in situ sites refer to cross-shore transects where ecological monitoring of presence/absence and abundance of macroalgae has been conducted by the Cawthron institute and related to the dredging of the harbour.

__Document Note__ : The maps, plots and app within this document are interactive so make sure you give them a play like zooming in and out in the maps but also on the plots. Clicking on the legend allows to only select and display the time series needed.

# Table of contents

1. [KPAR](#kpar)
  * [Mean](#kpar_mean)
  * [Availability of pixels](#kpar_availability)

2. [SST](#sst)
  * [Mean](#sst_mean)
  * [Availability of pixels](#sst_availability)
  * [Conclusion and further Work](#conclusion)

3. [Scenario 1](#scenario1)
  * [KPAR](#s1_kpar)
  * [SST](#s1_sst)
  * [Conclusion and further Work](#conclusion_s1)

4. [Scenario 2](#scenario2)
  * [KPAR](#s2_kpar)
  * [SST](#s2_sst)
 
5. [Scenario 1 vs Scenario 2](#scenario1vs2)
  * [KPAR](#s1vss2_kpar)
  * [SST](#s1vss2_sst)
  
# KPAR <a name="kpar"></a>

The KPAR dataset consists of monthly means of the attenuation coefficient estimated using the absorption and backscattering coefficient using MODIS-AQUA measurements of the emergent flux, radiance leaving the water. The dataset runs from July 2002 to March 2019.

## Mean <a name="kpar_mean"></a>


```{r kpar_mean_map, fig.cap="Figure 1 -Mean KPAR product around Lyttelton harbour, NZ.", warning=F}
## Read site sheet
site <- read.csv(file=paste0(getwd(),'/Coords_sites.csv'))
##

## KPAR stack and mean
kpar_mean <- raster('A200207_201903_KPAR_Mean_Lyttelton_QAA.tif')
kpar <- stack('A200207_201903_KPAR_MO_Lyttelton_QAA.tif')
##

## Bathy of the zone NIWA grid
## Download Bathy, plot it with sites and transform as contour
bathy <- raster('Bathy_Lyttelton.tif')
bathy[bathy>0] <- NA
bathycontour <- rasterToContour(bathy)
bathycontour <- spTransform(bathycontour,crs("+proj=longlat +ellps=WGS84 +datum=WGS84 +towgs84=0,0,0"))
##

## Plot KPAR mean and sites on leaflet map
pal <- colorNumeric(rev(rainbow(10)), values(kpar_mean),
                    na.color = "transparent")

m <- leaflet(site) %>% setView(lng = 173, lat = -43.55, zoom = 10) %>%
  addTiles()  %>%# Print the map
  addScaleBar(position = "bottomright",options = scaleBarOptions(imperial=F)) %>% 
  addMouseCoordinates() %>%
  addMarkers(site, lat = ~lat,lng = ~lon, popup = ~name) %>%
  addRasterImage(kpar_mean,layerId = "Kd (/m)", col=pal, opacity = 0.8,project=T) %>%
  addLegend(pal = pal, values = values(kpar_mean),title = "Kd (m-1)") %>%
  addImageQuery(x=kpar_mean,layerId = "Kd (/m)",type='click',project=T,position='bottomleft') %>%
  addPolylines(data=bathycontour,color = "black",opacity=0.2,popup = bathycontour$level)
m
```
Key observations:

  * Some high values for pixels close to shore. This over-estimation could be due to the 'land adjacency effect' which is due to the land being an near infra-red (NIR) bright target which create a NIR halo affecting the atmospheric correction (Matt explanation).
  * To think about a method to take different pixes into account for the estimation of the KPAR value a the site. Maybe a compromise to find between the distance to the site and the availability of the pixel. Also possible to take more pixels into account.

## Availability of pixels <a name="kpar_availability"></a>

```{r kpar_availability_map, fig.cap="Figure 2 - Availability of pixels for the KPAR product around Lyttelton harbour, NZ.", warning=F}

kpar_NA_sum <- raster('A200207_201903_KPAR_PixAvailability_Lyttelton.tif')

kpar_NA_sum_proj <- projectRaster(kpar_NA_sum,crs=crs("+proj=longlat +ellps=WGS84 +datum=WGS84 +towgs84=0,0,0"),method='ngb')

pal <- colorNumeric(rev(heat.colors(100)), values(kpar_NA_sum_proj),
                    na.color = "transparent")

m <- leaflet(site) %>% setView(lng = 173, lat = -43.55, zoom = 10) %>%
  addTiles()  %>%# Print the map
  addScaleBar(position = "bottomright",options = scaleBarOptions(imperial=F)) %>% 
  addMouseCoordinates() %>%
  addMarkers(site, lat = ~lat,lng = ~lon, popup = ~name) %>%
  addRasterImage(kpar_NA_sum_proj,layerId = "Number of pixels available", col=pal, opacity = 0.8) %>%
  addLegend(pal = pal, values = values(kpar_NA_sum_proj),title = "Number of pixels available") %>%
  addImageQuery(x=kpar_NA_sum_proj,layerId =  "Number of pixels available",type='click',position='bottomleft') %>%
  addPolylines(data=bathycontour,color = "black",opacity=0.2,popup = bathycontour$level)
m
```
Key observations:

  * The "holes" offshore in the pixels are likely to be due because of the reprojection for leaflet. Nothing to worry about.
  * Fewer pixels available close to shore/sites. As said previous section, to think about a method that takes into account the availability of pixels and distance to site.
  
# SST <a name="sst"></a>

The SST dataset runs from July 2002 to March 2019 and consists of monthly means. I don't know from which satellite it is from but could retrieve that at the occasion.

## Mean <a name="sst_mean"></a>

```{r sst_mean_map, fig.cap="Figure 3 - Mean SST product around Lyttelton harbour, NZ.", warning=F}

## SST stack and mean 
sst <- stack('A200207_201903_SST_MO_Lyttelton.tif')
sst_mean <- raster('A200207_201903_SST_Mean_Lyttelton.tif')
##

## Plot SST mean and sites on leaflet map
pal <- colorNumeric(rev(rainbow(100)), values(sst_mean),
                    na.color = "transparent")

m <- leaflet(site) %>% setView(lng = 173, lat = -43.55, zoom = 10) %>%
  addTiles()  %>%# Print the map
  addScaleBar(position = "bottomright",options = scaleBarOptions(imperial=F)) %>% 
  addMouseCoordinates() %>%
  addMarkers(site, lat = ~lat,lng = ~lon, popup = ~name) %>%
  addRasterImage(sst_mean,layerId = "SST (degC)", col=pal, opacity = 0.8,project=T) %>%
  addLegend(pal = pal, values = values(sst_mean),title = "SST (degC)") %>%
  addImageQuery(x=sst_mean,layerId =  "SST (degC)",type='click',project=T,position='bottomleft') %>%
  addPolylines(data=bathycontour,color = "black",opacity=0.2,popup = bathycontour$level)
m
```

Key observations:

  * Odd values in coastal pixels. Either too high? (in Lyttelton harbour and way out of bays) or too low? (within the bays).
  * As previously, to think about a method to get the SST estimated value by satellite to the sites.

## Availability of pixels <a name="sst_availability"></a>

```{r sst_availability_map, fig.cap="Figure 4 - Availability of pixels for the SST product around Lyttelton harbour, NZ.", warning=F}
sst_NA_sum <- raster('A200207_201903_SST_PixAvailability_Lyttelton.tif')

pal <- colorNumeric(rev(heat.colors(100)), values(sst_NA_sum),
                    na.color = "transparent")

m <- leaflet(site) %>% setView(lng = 173, lat = -43.55, zoom = 10) %>%
  addTiles()  %>%# Print the map
  addScaleBar(position = "bottomright",options = scaleBarOptions(imperial=F)) %>% 
  addMouseCoordinates() %>%
  addMarkers(site, lat = ~lat,lng = ~lon, popup = ~name) %>%
  addRasterImage(sst_NA_sum,layerId = "Number of pixels available", col=pal, opacity = 0.8,project=T) %>%
  addLegend(pal = pal, values = values(sst_NA_sum),title = "Number of pixels available") %>%
  addImageQuery(x=sst_NA_sum,layerId =  "Number of pixels available",type='click',position='bottomleft',project=T) %>%
  addPolylines(data=bathycontour,color = "black",opacity=0.2,popup = bathycontour$level)
m
```
Key observations:

  * Less pixels available where dodgy values are suspected.


## Conclusion and further Work <a name="conclusion"></a>

* Because the sat data is available from 07/2002 to 03/2019, to define a time frame to refine the dataset. Use the surveys dates, maybe to focus on ecological data during the baseline period (19-20/01/17 BL1 to 5-8/12/17 BL3) and do another analysis with the data after dredging phase (DP1 only date to fell into sat data dataset range).
* I could then regenerate monthly means within the new time frame and start exploring different scenarios for assigning a value to sites.

Different scenarios:

* 1 : Extract values (KPAR and SST) at site pixel -> Will be not realistic because of missing values due to shore and effect of land.
* 2 : Extract values at pixel wiht highest availability from cluster of 16 pixels adjacent to site location.
* 2' : Extract values at closest pixel offshore above threshold of certain pixel availability.
* 3 : Extract values from cluster of pixels at certain distance of site and above threshold of pixel availability.


# Scenario 1 <a name="scenario1"></a>

In order to have estimates of KPAR and SST for each sites, we investigate here the scenario of extracting the time series of the pixel where the site is. This approach is supposed to fail as the sites are very coastal so prone to pixels unavailability due to cloud coverage as well as the land adjacency effect which leads to failure in the atmospheric correction process.

## KPAR <a name="s1_kpar"></a>

```{r s1_kpar, fig.cap="Figure 5 - Time series of KPAR (/m) at the 21 sites around Lyttelton harbour, NZ. The values are extracted from the pixels where the sites are (Scenario 1).", warning=F}

## Work on Lat/Lon of site coordinates, reptroject to utm
# Reprojection of sites lon/lat into tmerc (EBED crs)
LatLong_site <- data.frame(Y=site$lat,X=site$lon)
names(LatLong_site) <- c("Y","X")
coordinates(LatLong_site) <- ~ X + Y # longitude first
proj4string(LatLong_site) <- crs("+proj=longlat +ellps=WGS84 +datum=WGS84 +towgs84=0,0,0")
utm_sites <- spTransform(LatLong_site, crs( "+proj=tmerc +lat_0=0 +lon_0=173 +k=0.9996 +x_0=1600000 +y_0=10000000 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs"))
##

## Extract values of pixel availability at sites location
kpar_NA_sum_velox <- velox('A200207_201903_KPAR_PixAvailability_Lyttelton.tif')
kpar_NA_sum_sites <- kpar_NA_sum_velox$extract_points(utm_sites)
sst_NA_sum_velox <- velox('A200207_201903_SST_PixAvailability_Lyttelton.tif')
sst_NA_sum_sites <- sst_NA_sum_velox$extract_points(utm_sites)
##

## KPAR
kpar_velox <- velox('A200207_201903_KPAR_MO_Lyttelton_QAA.tif')
kpar_sites <- kpar_velox$extract_points(utm_sites)
kpar_sites_df <- data.frame(t(kpar_sites))

colnames(kpar_sites_df) <- site$name
rownames(kpar_sites_df) <- NULL
dateseq <- seq.Date(as.Date("2002/7/1"), by = "month", length.out = dim(kpar_sites)[2])
kpar_sites_df$Date <- dateseq

kpar_sites_tb <- as_tibble(kpar_sites_df)
kpar_sites_tb <- kpar_sites_tb %>% pivot_longer(-Date,names_to="Site",values_to='Kpar') %>% group_by(Date)

q <- ggplot(kpar_sites_tb,aes(Date,Kpar,color=Site)) + geom_point() + geom_line() + labs(y="Kpar (/m)", x = "Date")
ggplotly(q)
```
Relevant observations: 

* No values for sites: PL14, PL03, PB10, PB11, PB03, PB02.
* Very frequent gaps in time series.
* Most of the values are over 0.2 /m and under 1 /m. Possible overestimation.

```{r, warning=F}
## KPAR mean, sd, median, min and max values over period
summary_kpar <- kpar_sites_tb %>% group_by(Site) %>% summarise(Mean=mean(Kpar,na.rm=T),Sd=sd(Kpar,na.rm=T),Median=median(Kpar,na.rm=T),Min=min(Kpar,na.rm=T),Max=max(Kpar,na.rm=T))
summary_kpar$PixAv <- kpar_NA_sum_sites
kable(summary_kpar)
```

## SST <a name="s1_sst"></a>

```{r s1_sst, fig.cap="Figure 6 - Time series of SST (degC) at the 21 sites around Lyttelton harbour, NZ. The values are extracted from the pixels where the sites are (Scenario 1).", warning=F}
sst_velox <- velox('A200207_201903_SST_MO_Lyttelton.tif')
sst_sites <- sst_velox$extract_points(utm_sites)
sst_sites_df <- data.frame(t(sst_sites))

colnames(sst_sites_df) <- site$name
rownames(sst_sites_df) <- NULL
dateseq <- seq.Date(as.Date("2002/7/1"), by = "month", length.out = dim(sst_sites)[2])
sst_sites_df$Date <- dateseq

sst_sites_tb <- as_tibble(sst_sites_df)
sst_sites_tb <- sst_sites_tb %>% pivot_longer(-Date,names_to="Site",values_to='SST') %>% group_by(Date)

p <- ggplot(sst_sites_tb,aes(Date,SST,color=Site)) + geom_point() + geom_line() + labs(y="SST (degC)", x = "Date")
ggplotly(p)
```
Relevant observations: 

* No values for sites: PL03, PB11, PB10, PB03, PB02.
* Very frequent gaps in time series. Some sites only have a few points (PL14), whereas others have only a few missing values (All BP for instance).
* Most of the values are over 10 degC (Winter) and under 20 degC (Summer). Seems relatively good, however let's have a look at the mean for every stations and see how the gaps in time series will affect the mean.

```{r, warning=F}
## SST mean, sd, median, min and max values over period
summary_sst <- sst_sites_tb %>% group_by(Site) %>% summarise(Mean=mean(SST,na.rm=T),Sd=sd(SST,na.rm=T),Median=median(SST,na.rm=T),Min=min(SST,na.rm=T),Max=max(SST,na.rm=T))
summary_sst$PixAv <- sst_NA_sum_sites
kable(summary_sst)
```

## Conclusion and further Work <a name="conclusion_s1"></a>

* The relative high number of missing values as well as the possible impact of the adjacent land lead to the conclusion that the scenario 1-way of getting estimated values for each site does not seem to show realistic values.
* Let's carry on the exploration and analyse the other scenarios.


# Scenario 2 <a name="scenario2"></a>

In order to have estimates of KPAR and SST for each sites, we investigate here the scenario of extracting the time series from a pixel with the maximum availability (using the pixel availability raster) within a cluster of 16 pixels adjacent to the site location (17 pixels including site, see what's the structure of the cluster).

## KPAR <a name="s2_kpar"></a>

```{r s2_kpar, fig.cap="Figure 7 - Time series of KPAR (/m) at the 21 sites around Lyttelton harbour, NZ. The values are extracted from the pixels with the highest availability in a cluster of 16 pixels adjacent to each sites. Scenario 2.", warning=F}
## KPAR
ngb_pix_maxPixAv_index_save <- c()
sites_kpar_mean_save <- c()
for (i in 1:dim(site)[1]) {
  sites_tmerc <- data.frame(utm_sites)[i,]
  sites_kpar_mean <- raster::extract(kpar_mean,sites_tmerc,cellnumbers=T) #Get cell number of pixel where site
  ngb_pixels <- raster::adjacent(kpar_mean,cells=sites_kpar_mean[,1],pairs=F,directions=16,include=T)
  
  ngb_pix_maxPixAv_index <- ngb_pixels[which(kpar_NA_sum[ngb_pixels]==max(kpar_NA_sum[ngb_pixels]))] #Return index of pixel in cluster of 16 pixels around that have max pixel availability
  # Issues with PB10 and PB3 -> Seems like no pixels available in vicinity
  if (length(ngb_pix_maxPixAv_index)>1) { 
    #Manually solve the issue affecting original index to pixel
    ngb_pix_maxPixAv_index <- sites_kpar_mean[,1]
  }
  ngb_pix_maxPixAv_index_save <- c(ngb_pix_maxPixAv_index_save,ngb_pix_maxPixAv_index)
}

# Position of the "new" pixels where extractions of scenario 2 is from
pix_index_maxPixAv <- xyFromCell(kpar_mean,cell=ngb_pix_maxPixAv_index_save,spatial=F)#Convert to sp feature, to use velox::
Tmerc_site_s2 <- data.frame(Y=pix_index_maxPixAv[,2],X=pix_index_maxPixAv[,1])
coordinates(Tmerc_site_s2) <- ~ X + Y # longitude first
proj4string(Tmerc_site_s2) <- crs("+proj=tmerc +lat_0=0 +lon_0=173 +k=0.9996 +x_0=1600000 +y_0=10000000 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs")
LatLong_sites_s2 <- spTransform(Tmerc_site_s2,crs("+proj=longlat +ellps=WGS84 +datum=WGS84 +towgs84=0,0,0"))
LatLong_sites_s2$name <- paste0(site$name,"_s2")
LatLong_sites_s2_df <- data.frame(LatLong_sites_s2)

# Extract time series from "new" pixels
pix_index_maxPixAv_sp <- xyFromCell(kpar_mean,cell=ngb_pix_maxPixAv_index_save,spatial=T)#Convert to sp feature, to use velox::
kpar_sites_maxPixAv <- kpar_velox$extract_points(pix_index_maxPixAv_sp)#Classic extraction process
kpar_sites_maxPixAv_df <- data.frame(t(kpar_sites_maxPixAv))

colnames(kpar_sites_maxPixAv_df) <- LatLong_sites_s2$name#paste0(site$name[1],'_maxPixAv')
rownames(kpar_sites_maxPixAv_df) <- NULL
dateseq <- seq.Date(as.Date("2002/7/1"), by = "month", length.out = dim(kpar_sites_maxPixAv_df)[1])
kpar_sites_maxPixAv_df$Date <- dateseq

kpar_sites_maxPixAv_tb <- as_tibble(kpar_sites_maxPixAv_df)
kpar_sites_maxPixAv_tb <- kpar_sites_maxPixAv_tb %>% pivot_longer(-Date,names_to="Site",values_to='Kpar') %>% group_by(Date)

q <- ggplot(kpar_sites_maxPixAv_tb,aes(Date,Kpar,color=Site)) + geom_point() + geom_line() + labs(y="Kpar (/m)", x = "Date")
ggplotly(q)
```

```{r s2_kpar_map, fig.cap="Figure 8 - Position of the Pixels where time series are extracted in the scenario 2 case.", warning=F}
m <- leaflet(data=LatLong_sites_s2_df) %>% setView(lng = 173, lat = -43.55, zoom = 10) %>%
  addTiles()  %>%# Print the map
  addMarkers(LatLong_sites_s2_df, lat = ~Y,lng = ~X, popup = ~name)
m
```

Relevant observations: 

* TO FILL (Less gap, Position of the new pixels, PB03 and PB10 no value coz no ngb)

```{r, warning=F}
## KPAR mean, sd, median, min and max values over period
summary_kpar_s2 <- kpar_sites_maxPixAv_tb %>% group_by(Site) %>% summarise(Mean=mean(Kpar,na.rm=T),Sd=sd(Kpar,na.rm=T),Median=median(Kpar,na.rm=T),Min=min(Kpar,na.rm=T),Max=max(Kpar,na.rm=T))
summary_kpar_s2$PixAv <- kpar_NA_sum[ngb_pix_maxPixAv_index_save]
kable(summary_kpar_s2)
```


## SST <a name="s2_sst"></a>

```{r s2_sst, fig.cap="Figure 9 - Time series of SST (degC) at the 21 sites around Lyttelton harbour, NZ. The values are extracted from the pixels with the highest availability in a cluster of 16 pixels adjacent to each sites. Scenario 2.", warning=F}
## SST
ngb_pix_maxPixAv_index_save <- c()
sites_sst_mean_save <- c()
for (i in 1:dim(site)[1]) {
  sites_tmerc <- data.frame(utm_sites)[i,]
  sites_sst_mean <- raster::extract(kpar_mean,sites_tmerc,cellnumbers=T) #Get cell number of pixel where site
  ngb_pixels <- raster::adjacent(sst_mean,cells=sites_sst_mean[,1],pairs=F,directions=16,include=T)
  
  ngb_pix_maxPixAv_index <- ngb_pixels[which(sst_NA_sum[ngb_pixels]==max(sst_NA_sum[ngb_pixels]))] #Return index of pixel in cluster of 16 pixels around that have max pixel availability
  # Issues with PB10 and PB3 -> Seems like no pixels available in vicinity
  if (length(ngb_pix_maxPixAv_index)>1) { 
    #Manually solve the issue affecting original index to pixel
    ngb_pix_maxPixAv_index <- sites_sst_mean[,1]
  }
  ngb_pix_maxPixAv_index_save <- c(ngb_pix_maxPixAv_index_save,ngb_pix_maxPixAv_index)
}

# Position of the "new" pixels where extractions of scenario 2 is from
pix_index_maxPixAv_sst <- xyFromCell(sst_mean,cell=ngb_pix_maxPixAv_index_save,spatial=F)#Convert to sp feature, to use velox::
Tmerc_site_s2_sst <- data.frame(Y=pix_index_maxPixAv_sst[,2],X=pix_index_maxPixAv_sst[,1])
coordinates(Tmerc_site_s2_sst) <- ~ X + Y # longitude first
proj4string(Tmerc_site_s2_sst) <- crs("+proj=tmerc +lat_0=0 +lon_0=173 +k=0.9996 +x_0=1600000 +y_0=10000000 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs")
LatLong_sites_s2_sst <- spTransform(Tmerc_site_s2_sst,crs("+proj=longlat +ellps=WGS84 +datum=WGS84 +towgs84=0,0,0"))
LatLong_sites_s2_sst$name <- paste0(site$name,"_s2")
LatLong_sites_s2_sst_df <- data.frame(LatLong_sites_s2_sst)

# Extract time series from "new" pixels
pix_index_maxPixAv_sp <- xyFromCell(sst_mean,cell=ngb_pix_maxPixAv_index_save,spatial=T)#Convert to sp feature, to use velox::
sst_sites_maxPixAv <- sst_velox$extract_points(pix_index_maxPixAv_sp)#Classic extraction process
sst_sites_maxPixAv_df <- data.frame(t(sst_sites_maxPixAv))

colnames(sst_sites_maxPixAv_df) <- LatLong_sites_s2_sst$name#paste0(site$name[1],'_maxPixAv')
rownames(sst_sites_maxPixAv_df) <- NULL
dateseq <- seq.Date(as.Date("2002/7/1"), by = "month", length.out = dim(sst_sites_maxPixAv_df)[1])
sst_sites_maxPixAv_df$Date <- dateseq

sst_sites_maxPixAv_tb <- as_tibble(sst_sites_maxPixAv_df)
sst_sites_maxPixAv_tb <- sst_sites_maxPixAv_tb %>% pivot_longer(-Date,names_to="Site",values_to='SST') %>% group_by(Date)

q <- ggplot(sst_sites_maxPixAv_tb,aes(Date,SST,color=Site)) + geom_point() + geom_line() + labs(y="SST (degC)", x = "Date")
ggplotly(q)
```

```{r s2_sst_map, fig.cap="Figure 10 - Position of the pixels where time series of SST are extracted from in the scenario 2 case.", warning=F}
m <- leaflet(data=LatLong_sites_s2_sst_df) %>% setView(lng = 173, lat = -43.55, zoom = 10) %>%
  addTiles()  %>%
  addMarkers(LatLong_sites_s2_sst_df, lat = ~Y,lng = ~X, popup = ~name)
m
```

Relevant observations: 

* TO FILL (Less gap, Position of the new pixels, PB03 and PB10 no value coz no ngb, PL02 new pixel is in LH.)

```{r, warning=F}
## KPAR mean, sd, median, min and max values over period
# SST mean, sd, median, min and max values over period
summary_sst_s2 <- sst_sites_maxPixAv_tb %>% group_by(Site) %>% summarise(Mean=mean(SST,na.rm=T),Sd=sd(SST,na.rm=T),Median=median(SST,na.rm=T),Min=min(SST,na.rm=T),Max=max(SST,na.rm=T))
summary_sst_s2$PixAv <- sst_NA_sum[ngb_pix_maxPixAv_index_save]
kable(summary_sst_s2)
```


# Scenario 1 vs Scenario 2 <a name="scenario1vs2"></a>

The following tables show the difference of the values from the scenario 1 minus scenario 2 for each sites. Negative values mean that the scenario 2 leads to an increase in the parameter/value from scenario 1.

## KPAR <a name="s1vss2_kpar"></a>

```{r, warning=F}
## KPAR - Relative difference: s1 - s2
is.na(summary_kpar) <- sapply(summary_kpar, is.infinite)#Replace INF value by NA
is.na(summary_kpar_s2) <- sapply(summary_kpar_s2, is.infinite)#Replace INF value by NA
rdiff_s1s2_kpar <- summary_kpar[,2:7] - summary_kpar_s2[,2:7]
rdiff_s1s2_kpar$Site <- summary_kpar$Site
kable(rdiff_s1s2_kpar)
##
```
Key observations:

  * Considerable gain of pixel availability, except for 6 sites.
  * Not relevant methods for 6 sites where originally NA.
  * Scenario 2 leads to decrease of KPAR mean.

## SST <a name="s1vss2_sst"></a>

```{r, warning=F}
## SST - Relative difference: s1 - s2
is.na(summary_sst) <- sapply(summary_sst, is.infinite)#Replace INF value by NA
is.na(summary_sst_s2) <- sapply(summary_sst_s2, is.infinite)#Replace INF value by NA
rdiff_s1s2_sst <- summary_sst[,2:7] - summary_sst_s2[,2:7]
rdiff_s1s2_sst$Site <- summary_sst$Site
kable(rdiff_s1s2_sst)
```
Key observations:

  * Considerable gain of pixel availability, except for 5 sites.
  * Not relevant methods for 5 sites where originally NA
  * Scenario 2 leads to decrease of SST mean except at 4 sites (BP05, LH02, PL02, PL14).
  * PB02 wtf, to check


